{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steel Industry Energy Consumption Prediction\n",
    "## AI-Powered Energy Analytics for Sustainable Manufacturing\n",
    "\n",
    "**Author:** [Your Name]  \n",
    "**Student ID:** [Your Student ID]  \n",
    "**Module:** M516 Business Project in Big Data & AI  \n",
    "**Date:** December 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This project develops an AI-based system for predicting energy consumption in steel manufacturing, supporting sustainability goals through:\n",
    "\n",
    "1. **Energy Consumption Prediction** - Regression models to forecast kWh usage\n",
    "2. **Load Type Classification** - Classify operational load (Light/Medium/Maximum)\n",
    "3. **Sustainability Insights** - CO2 emission analysis and optimization recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,\n",
    "                             accuracy_score, classification_report, confusion_matrix)\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Steel Industry Energy Consumption Dataset\n",
    "df = pd.read_csv('data/Steel_industry_data.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(\"=\"*50)\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary of Numerical Features\n",
    "print(\"Statistical Summary:\")\n",
    "print(\"=\"*70)\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Target Variable (Energy Consumption)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['Usage_kWh'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].set_xlabel('Energy Consumption (kWh)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Energy Consumption', fontsize=14)\n",
    "axes[0].axvline(df['Usage_kWh'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"Usage_kWh\"].mean():.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box Plot\n",
    "axes[1].boxplot(df['Usage_kWh'], vert=True)\n",
    "axes[1].set_ylabel('Energy Consumption (kWh)', fontsize=12)\n",
    "axes[1].set_title('Box Plot of Energy Consumption', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/energy_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Type Distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "load_counts = df['Load_Type'].value_counts()\n",
    "colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "bars = ax.bar(load_counts.index, load_counts.values, color=colors, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Load Type', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title('Distribution of Load Types', fontsize=14)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, load_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 200, \n",
    "            f'{val:,}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/load_type_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLoad Type Percentages:\")\n",
    "print((load_counts / len(df) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation = df[numeric_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "sns.heatmap(correlation, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "            center=0, ax=ax, square=True, linewidths=0.5)\n",
    "ax.set_title('Correlation Matrix - Steel Industry Energy Data', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Consumption by Load Type\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "load_order = ['Light_Load', 'Medium_Load', 'Maximum_Load']\n",
    "\n",
    "# Box plot\n",
    "sns.boxplot(x='Load_Type', y='Usage_kWh', data=df, order=load_order, ax=axes[0], palette='Set2')\n",
    "axes[0].set_title('Energy Consumption by Load Type', fontsize=14)\n",
    "axes[0].set_xlabel('Load Type', fontsize=12)\n",
    "axes[0].set_ylabel('Energy Consumption (kWh)', fontsize=12)\n",
    "\n",
    "# Violin plot\n",
    "sns.violinplot(x='Load_Type', y='Usage_kWh', data=df, order=load_order, ax=axes[1], palette='Set2')\n",
    "axes[1].set_title('Energy Consumption Distribution by Load Type', fontsize=14)\n",
    "axes[1].set_xlabel('Load Type', fontsize=12)\n",
    "axes[1].set_ylabel('Energy Consumption (kWh)', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/energy_by_load_type.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based Analysis\n",
    "df['Hour'] = (df['NSM'] / 3600).astype(int)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Hourly average consumption\n",
    "hourly_avg = df.groupby('Hour')['Usage_kWh'].mean()\n",
    "axes[0, 0].plot(hourly_avg.index, hourly_avg.values, marker='o', linewidth=2, color='steelblue')\n",
    "axes[0, 0].fill_between(hourly_avg.index, hourly_avg.values, alpha=0.3)\n",
    "axes[0, 0].set_xlabel('Hour of Day', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Average Energy (kWh)', fontsize=12)\n",
    "axes[0, 0].set_title('Average Energy Consumption by Hour', fontsize=14)\n",
    "axes[0, 0].set_xticks(range(0, 24, 2))\n",
    "\n",
    "# Daily consumption by weekday\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_avg = df.groupby('Day_of_week')['Usage_kWh'].mean().reindex(day_order)\n",
    "axes[0, 1].bar(daily_avg.index, daily_avg.values, color='steelblue', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Day of Week', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Average Energy (kWh)', fontsize=12)\n",
    "axes[0, 1].set_title('Average Energy Consumption by Day', fontsize=14)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Weekend vs Weekday\n",
    "week_status_avg = df.groupby('WeekStatus')['Usage_kWh'].mean()\n",
    "axes[1, 0].bar(week_status_avg.index, week_status_avg.values, \n",
    "               color=['coral', 'lightgreen'], edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Week Status', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Average Energy (kWh)', fontsize=12)\n",
    "axes[1, 0].set_title('Energy Consumption: Weekday vs Weekend', fontsize=14)\n",
    "\n",
    "# CO2 vs Energy consumption\n",
    "sample = df.sample(min(2000, len(df)), random_state=42)\n",
    "axes[1, 1].scatter(sample['Usage_kWh'], sample['CO2(tCO2)'], alpha=0.5, s=20, c='green')\n",
    "axes[1, 1].set_xlabel('Energy Consumption (kWh)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('CO2 Emissions (tCO2)', fontsize=12)\n",
    "axes[1, 1].set_title('Energy Consumption vs CO2 Emissions', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/time_series_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the dataset for modeling.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Extract hour from NSM\n",
    "    df['Hour'] = (df['NSM'] / 3600).astype(int)\n",
    "    \n",
    "    # Create time period\n",
    "    def get_time_period(hour):\n",
    "        if 0 <= hour < 6:\n",
    "            return 'Night'\n",
    "        elif 6 <= hour < 12:\n",
    "            return 'Morning'\n",
    "        elif 12 <= hour < 18:\n",
    "            return 'Afternoon'\n",
    "        else:\n",
    "            return 'Evening'\n",
    "    \n",
    "    df['Time_Period'] = df['Hour'].apply(get_time_period)\n",
    "    \n",
    "    # Is Peak Hour (8 AM - 6 PM on weekdays)\n",
    "    df['Is_Peak_Hour'] = ((df['Hour'] >= 8) & (df['Hour'] <= 18) & \n",
    "                          (df['WeekStatus'] == 'Weekday')).astype(int)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_week = LabelEncoder()\n",
    "    le_day = LabelEncoder()\n",
    "    le_time = LabelEncoder()\n",
    "    le_load = LabelEncoder()\n",
    "    \n",
    "    df['WeekStatus_encoded'] = le_week.fit_transform(df['WeekStatus'])\n",
    "    df['Day_of_week_encoded'] = le_day.fit_transform(df['Day_of_week'])\n",
    "    df['Time_Period_encoded'] = le_time.fit_transform(df['Time_Period'])\n",
    "    df['Load_Type_encoded'] = le_load.fit_transform(df['Load_Type'])\n",
    "    \n",
    "    return df, le_load\n",
    "\n",
    "# Apply preprocessing\n",
    "df_processed, load_encoder = preprocess_data(df)\n",
    "print(\"Preprocessing completed!\")\n",
    "print(f\"\\nNew features created: Hour, Time_Period, Is_Peak_Hour\")\n",
    "print(f\"Encoded columns: WeekStatus, Day_of_week, Time_Period, Load_Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns for regression\n",
    "feature_cols_regression = [\n",
    "    'Lagging_Current_Reactive.Power_kVarh',\n",
    "    'Leading_Current_Reactive_Power_kVarh',\n",
    "    'CO2(tCO2)',\n",
    "    'Lagging_Current_Power_Factor',\n",
    "    'Leading_Current_Power_Factor',\n",
    "    'NSM',\n",
    "    'Hour',\n",
    "    'Is_Peak_Hour',\n",
    "    'WeekStatus_encoded',\n",
    "    'Day_of_week_encoded',\n",
    "    'Time_Period_encoded',\n",
    "    'Load_Type_encoded'\n",
    "]\n",
    "\n",
    "# Define feature columns for classification (exclude Load_Type)\n",
    "feature_cols_classification = [\n",
    "    'Usage_kWh',\n",
    "    'Lagging_Current_Reactive.Power_kVarh',\n",
    "    'Leading_Current_Reactive_Power_kVarh',\n",
    "    'CO2(tCO2)',\n",
    "    'Lagging_Current_Power_Factor',\n",
    "    'Leading_Current_Power_Factor',\n",
    "    'NSM',\n",
    "    'Hour',\n",
    "    'Is_Peak_Hour',\n",
    "    'WeekStatus_encoded',\n",
    "    'Day_of_week_encoded',\n",
    "    'Time_Period_encoded'\n",
    "]\n",
    "\n",
    "print(f\"Regression Features: {len(feature_cols_regression)}\")\n",
    "print(f\"Classification Features: {len(feature_cols_classification)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Model Training - Energy Consumption Prediction (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression\n",
    "X_reg = df_processed[feature_cols_regression]\n",
    "y_reg = df_processed['Usage_kWh']\n",
    "\n",
    "# Train-test split\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train_reg.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_reg.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression models\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "reg_results = []\n",
    "\n",
    "print(\"Training Regression Models...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_reg, y_train_reg)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_reg)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test_reg, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_reg, y_pred)\n",
    "    r2 = r2_score(y_test_reg, y_pred)\n",
    "    \n",
    "    reg_results.append({\n",
    "        'Model': name,\n",
    "        'R2_Score': round(r2, 4),\n",
    "        'RMSE': round(rmse, 4),\n",
    "        'MAE': round(mae, 4),\n",
    "        'MSE': round(mse, 4)\n",
    "    })\n",
    "    \n",
    "    print(f\"  R2 Score: {r2:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "\n",
    "# Create results dataframe\n",
    "reg_results_df = pd.DataFrame(reg_results).sort_values('R2_Score', ascending=False)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REGRESSION MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "reg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Regression Results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(reg_results_df)))\n",
    "bars = ax.barh(reg_results_df['Model'], reg_results_df['R2_Score'], color=colors, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('RÂ² Score', fontsize=12)\n",
    "ax.set_title('Regression Model Comparison - RÂ² Score', fontsize=14)\n",
    "\n",
    "for bar, val in zip(bars, reg_results_df['R2_Score']):\n",
    "    ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.4f}', va='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/regression_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model - Actual vs Predicted\n",
    "best_model = regression_models['XGBoost']  # Using XGBoost as best performer\n",
    "y_pred_best = best_model.predict(X_test_reg)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test_reg, y_pred_best, alpha=0.5, s=20, c='steelblue')\n",
    "axes[0].plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Energy (kWh)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Energy (kWh)', fontsize=12)\n",
    "axes[0].set_title('Actual vs Predicted - XGBoost', fontsize=14)\n",
    "axes[0].legend()\n",
    "\n",
    "# Residual plot\n",
    "residuals = y_test_reg - y_pred_best\n",
    "axes[1].scatter(y_pred_best, residuals, alpha=0.5, s=20, c='green')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Predicted Energy (kWh)', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title('Residual Plot - XGBoost', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/actual_vs_predicted.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance - XGBoost\n",
    "importance = best_model.feature_importances_\n",
    "feature_importance = dict(zip(feature_cols_regression, importance))\n",
    "sorted_importance = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "features = list(sorted_importance.keys())\n",
    "importances = list(sorted_importance.values())\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(features)))[::-1]\n",
    "\n",
    "ax.barh(features, importances, color=colors, edgecolor='black')\n",
    "ax.set_xlabel('Importance', fontsize=12)\n",
    "ax.set_title('Feature Importance - XGBoost Regressor', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/feature_importance_regression.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "for i, (feat, imp) in enumerate(list(sorted_importance.items())[:5], 1):\n",
    "    print(f\"{i}. {feat}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Model Training - Load Type Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for classification\n",
    "X_clf = df_processed[feature_cols_classification]\n",
    "y_clf = df_processed['Load_Type_encoded']\n",
    "\n",
    "# Train-test split\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train_clf.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_clf.shape[0]} samples\")\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(pd.Series(y_test_clf).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classification models\n",
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, verbosity=0, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "clf_results = []\n",
    "\n",
    "print(\"Training Classification Models...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_clf, y_train_clf)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_clf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_clf, y_pred)\n",
    "    \n",
    "    clf_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': round(accuracy, 4)\n",
    "    })\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Create results dataframe\n",
    "clf_results_df = pd.DataFrame(clf_results).sort_values('Accuracy', ascending=False)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "clf_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Classification Model - Confusion Matrix\n",
    "best_clf_model = classification_models['XGBoost']\n",
    "y_pred_clf = best_clf_model.predict(X_test_clf)\n",
    "\n",
    "# Get class names\n",
    "class_names = load_encoder.classes_\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_clf, y_pred_clf)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "ax.set_title('Confusion Matrix - XGBoost Classifier', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test_clf, y_pred_clf, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Classification Results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.plasma(np.linspace(0.2, 0.8, len(clf_results_df)))\n",
    "bars = ax.barh(clf_results_df['Model'], clf_results_df['Accuracy'], color=colors, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Classification Model Comparison - Accuracy', fontsize=14)\n",
    "ax.set_xlim(0, 1.1)\n",
    "\n",
    "for bar, val in zip(bars, clf_results_df['Accuracy']):\n",
    "    ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.4f}', va='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/classification_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Sustainability Insights - CO2 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO2 Emissions Analysis\n",
    "print(\"CO2 Emissions Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Correlation between CO2 and Energy\n",
    "co2_energy_corr = df['CO2(tCO2)'].corr(df['Usage_kWh'])\n",
    "print(f\"\\nCorrelation between CO2 and Energy: {co2_energy_corr:.4f}\")\n",
    "\n",
    "# CO2 by Load Type\n",
    "co2_by_load = df.groupby('Load_Type')['CO2(tCO2)'].agg(['mean', 'sum']).round(4)\n",
    "print(\"\\nCO2 Emissions by Load Type:\")\n",
    "print(co2_by_load)\n",
    "\n",
    "# CO2 by Week Status\n",
    "co2_by_week = df.groupby('WeekStatus')['CO2(tCO2)'].agg(['mean', 'sum']).round(4)\n",
    "print(\"\\nCO2 Emissions by Week Status:\")\n",
    "print(co2_by_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustainability Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# CO2 by Load Type\n",
    "co2_mean = df.groupby('Load_Type')['CO2(tCO2)'].mean().reindex(load_order)\n",
    "colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "axes[0].bar(co2_mean.index, co2_mean.values * 1000, color=colors, edgecolor='black')  # Convert to kg\n",
    "axes[0].set_xlabel('Load Type', fontsize=12)\n",
    "axes[0].set_ylabel('Average CO2 Emissions (kg)', fontsize=12)\n",
    "axes[0].set_title('Average CO2 Emissions by Load Type', fontsize=14)\n",
    "\n",
    "# Hourly CO2 emissions\n",
    "hourly_co2 = df.groupby('Hour')['CO2(tCO2)'].mean() * 1000\n",
    "axes[1].fill_between(hourly_co2.index, hourly_co2.values, alpha=0.5, color='green')\n",
    "axes[1].plot(hourly_co2.index, hourly_co2.values, marker='o', linewidth=2, color='darkgreen')\n",
    "axes[1].set_xlabel('Hour of Day', fontsize=12)\n",
    "axes[1].set_ylabel('Average CO2 Emissions (kg)', fontsize=12)\n",
    "axes[1].set_title('Average CO2 Emissions by Hour', fontsize=14)\n",
    "axes[1].set_xticks(range(0, 24, 2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/co2_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š DATASET OVERVIEW:\")\n",
    "print(f\"   - Total Records: {len(df):,}\")\n",
    "print(f\"   - Features: {len(df.columns)}\")\n",
    "print(f\"   - Time Period: Full year 2018 (15-minute intervals)\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ REGRESSION RESULTS (Energy Prediction):\")\n",
    "best_reg = reg_results_df.iloc[0]\n",
    "print(f\"   - Best Model: {best_reg['Model']}\")\n",
    "print(f\"   - RÂ² Score: {best_reg['R2_Score']:.4f}\")\n",
    "print(f\"   - RMSE: {best_reg['RMSE']:.4f} kWh\")\n",
    "print(f\"   - MAE: {best_reg['MAE']:.4f} kWh\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ CLASSIFICATION RESULTS (Load Type):\")\n",
    "best_clf = clf_results_df.iloc[0]\n",
    "print(f\"   - Best Model: {best_clf['Model']}\")\n",
    "print(f\"   - Accuracy: {best_clf['Accuracy']:.4f} ({best_clf['Accuracy']*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nðŸŒ± SUSTAINABILITY INSIGHTS:\")\n",
    "print(f\"   - CO2-Energy Correlation: {co2_energy_corr:.4f}\")\n",
    "print(f\"   - Maximum Load produces highest CO2 emissions\")\n",
    "print(f\"   - Peak hours (8 AM - 6 PM) have highest energy consumption\")\n",
    "\n",
    "print(\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "print(\"   1. Schedule heavy operations during off-peak hours\")\n",
    "print(\"   2. Monitor and optimize Maximum Load operations\")\n",
    "print(\"   3. Implement predictive maintenance using the ML models\")\n",
    "print(\"   4. Use real-time predictions for energy management\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "reg_results_df.to_csv('results/regression_results.csv', index=False)\n",
    "clf_results_df.to_csv('results/classification_results.csv', index=False)\n",
    "\n",
    "print(\"Results saved successfully!\")\n",
    "print(\"- results/regression_results.csv\")\n",
    "print(\"- results/classification_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "1. Sathishkumar V E, Shin C., Cho Y., \"Efficient energy consumption prediction model for a data analytic-enabled industry building in a smart city\", Building Research & Information, 2021.\n",
    "\n",
    "2. Dataset Source: Kaggle - Steel Industry Energy Consumption  \n",
    "   URL: https://www.kaggle.com/datasets/csafrit2/steel-industry-energy-consumption\n",
    "\n",
    "3. Scikit-learn Documentation: https://scikit-learn.org/stable/\n",
    "\n",
    "4. XGBoost Documentation: https://xgboost.readthedocs.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
